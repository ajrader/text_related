{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Rapid Development & High Performance Text Processing*\n",
      "\n",
      "#PyData NYC 2013\n",
      "##*Joint work with Ian Langmore"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#[Rosetta](https://github.com/columbia-applied-data-science/rosetta) \n",
      "\n",
      "##Tools for data science with a focus on text processing.\n",
      "\n",
      "* Focuses on \"medium data\", i.e. data too big to fit into memory but too small to necessitate the use of a cluster.\n",
      "* Integrates with existing scientific Python stack as well as select outside tools.\n",
      "\n",
      "## Tools and utilities \n",
      "\n",
      "### `cmd` \n",
      "* Unix-like command line utilities.  Filters (read from stdin/write to stdout) for files\n",
      "\n",
      "### `parallel` \n",
      "* Wrappers for Python multiprocessing that add ease of use\n",
      "* Memory-friendly multiprocessing\n",
      "\n",
      "### `text`\n",
      "* Stream text from disk to formats used in common ML processes\n",
      "* Write processed text to sparse formats\n",
      "* Helpers for ML tools (e.g. Vowpal Wabbit, Gensim, etc...)\n",
      "* Other general utilities\n",
      "\n",
      "### `workflow`\n",
      "* High-level wrappers that have helped with our workflow and provide additional examples of code use\n",
      "\n",
      "### `modeling`\n",
      "* General ML modeling utilities\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Lets begin"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#for the purpose of this tutorial we will be working with a \n",
      "#collection of about 1000 declassified government embassy cables\n",
      "#please download the cables at http://stat.columbia.edu/~langmore/PyData2013.zip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pwd\n",
      "cd PyDataNYC2013/PyDataNYC2013/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "u'C:\\\\Users\\\\AJ'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Text Processors"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Streamers\n",
      "* Data in many text processing problems comes in the form of \n",
      "    * flat files\n",
      "    * repeated calls to an DB or API\n",
      "    * some 'online' stream\n",
      "* A lot of these can be handled streaming the data either from disk, DB, API minimizing CPU use\n",
      "* In addition, a lot of streaming is embarassingly parallel so can be easily scaled\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd 'PyDataNYC2013/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\AJ\\PyDataNYC2013\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd 'GenSimTalk/'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "C:\\Users\\AJ\\PyDataNYC2013\\GenSimTalk\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#all you realy need to know is that CABLES is the directory where the data (or cables)\n",
      "#are stored on your machine\n",
      "#DATA = os.environ['DATA']\n",
      "#CABLES = os.path.join(DATA, 'prod', 'declass', 'cables_short')\n",
      "CABLES = './data'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Streaming: given a collection of objects streaming is the paradigm of processing these objects one at a time in memory, extracting relevant information, writing the information, and discarding the original object \n",
      "\n",
      "###Note: after a streaming process is complete, the original collection should no longer be needed for the analysis at hand"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Lets write a simple file streamer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#filefilter is a module which helps with basic file/dir functions, such as\n",
      "#retrieving all paths from a given directory and it's subdir's\n",
      "from rosetta.text import filefilter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def simple_file_streamer(base_path):\n",
      "    paths = filefilter.get_paths(base_path, get_iter=True)\n",
      "    for p in paths:\n",
      "        with open(p) as f:\n",
      "            text = f.read()\n",
      "            yield(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###In case you haven't worked much with iterators explicitely, here is a small refresher... \n",
      "* For those familiar with generator functions, or iterators, you'll notice that this is exactly what we mean by \"streamer,\" i.e. anything that retrieves files or extracts information from therein and has a .next() method\n",
      "* or you can checkout James Powell's talk from this and previous PyData conferences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# this is making your own iterator\n",
      "def my_iter(N):\n",
      "    i=0\n",
      "    while True:\n",
      "        if i == N:\n",
      "            raise StopIteration\n",
      "        else:\n",
      "            yield i\n",
      "        i += 1\n",
      "                \n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mi = my_iter(5)\n",
      "print mi.next()\n",
      "print mi.next()\n",
      "print mi.next()\n",
      "print mi.next()\n",
      "print mi.next()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mi.next()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "StopIteration",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-15-23ca07f45444>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mmi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-13-f1c22fa35803>\u001b[0m in \u001b[0;36mmy_iter\u001b[1;34m(N)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mStopIteration\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#note the raised StopIteration; lets see how a for look handles this\n",
      "\n",
      "for i in my_iter(5):\n",
      "    print i\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###so even if you have not thought about iterators, you have been using them throughout \n",
      "###now back to our streamer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "simple_stream = simple_file_streamer(CABLES)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lets look at what this object is\n",
      "type(simple_stream)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "generator"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Note: this is the first time anything is read into memory"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#lets see what the .next() yields (and splitlines to make it more readable)\n",
      "simple_stream.next().splitlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "['LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'PAGE 01  YAOUND 00572  01 OF 02  131742Z',\n",
        " '',\n",
        " '42',\n",
        " 'ACTION EB-07',\n",
        " '',\n",
        " 'INFO  OCT-01  AF-06  ARA-06  EUR-12  EA-07  NEA-10  ISO-00  OIC-02',\n",
        " '',\n",
        " '      ERDA-05  AID-05  CEA-01  CIAE-00  CIEP-01  COME-00  DODE-00',\n",
        " '',\n",
        " '      FEAE-00  FPC-01  H-02  INR-07  INT-05  L-03  NSAE-00  NSC-05',\n",
        " '',\n",
        " '      OMB-01  PM-04  USIA-06  SAM-01  OES-03  SP-02  SS-15  STR-04',\n",
        " '',\n",
        " '      TRSE-00  PA-01  PRS-01  IO-11  OPIC-03  XMB-02  IGA-02',\n",
        " '',\n",
        " '      DOTE-00  AGR-05  /147 W',\n",
        " '                       ---------------------     076160',\n",
        " 'R 131630Z FEB 76',\n",
        " 'FM AMEMBASSY YAOUNDE',\n",
        " 'TO SECSTATE WASHDC 7791',\n",
        " 'INFO AMEMBASSY ALGIERS',\n",
        " 'AMEMBASSY BELGRADE',\n",
        " 'AMEMBASSY BRASILIA',\n",
        " 'AMEMBASSY BUENOS AIRES',\n",
        " 'AMEMBASSY CAIRO',\n",
        " 'AMEMBASSY CARACAS',\n",
        " 'AMEMBASSY JAKARTA',\n",
        " 'AMEMBASSY ISLAMABAD',\n",
        " 'AMEMBASSY JIDDA',\n",
        " 'AMEMBASSY KINGSTON',\n",
        " 'AMEMBASSY KINSHASA',\n",
        " 'AMEMBASSY LAGOS',\n",
        " 'AMEMBASSY LIMA',\n",
        " 'AMEMBASSY LUSAKA',\n",
        " 'AMEMBASSY MEXICO',\n",
        " 'AMEMBASSY NEW DELHI',\n",
        " 'AMEMBASSY PARIS',\n",
        " 'USMISSION USUN',\n",
        " 'AMCONSUL DOUALA',\n",
        " '',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE SECTION 1 OF 2 YAOUNDE 0572',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'PAGE 02  YAOUND 00572  01 OF 02  131742Z',\n",
        " '',\n",
        " 'PARIS FOR CIEC DELEGATION',\n",
        " '',\n",
        " 'E.O. 11652:  NA',\n",
        " 'TAGS:  CIEC, EGEN, CM',\n",
        " 'SUBJECT:  PRESIDENT AHIDJO SPEAKS ON CIEC',\n",
        " '',\n",
        " 'REF:  STATE 20560',\n",
        " '',\n",
        " '1.  SUMMARY.  IN INTERVIEW PUBLISHED FEBRUARY 7, PRESIDENT AHIDJO GAV',\n",
        " 'E',\n",
        " 'CAREFULLY FORMULATED PRESENTATION OF GURC VIEWS ON CIEC.',\n",
        " 'RE ENERGY, AHIDJO CITED NEED WORK FOR PROTECTION OF',\n",
        " 'PURCHASING POWER OF OIL PRODUCERS, DEVELOPMENT OF',\n",
        " 'ALTERNATIVE ENERGY SOURCES (SOLAR, HYDROELECTRIC, ETC.)',\n",
        " 'AND ESTABLISHMENT OF ASSURED PETROLEUM SUPPLIES FOR',\n",
        " 'CONSUMERS.  RE RAW MATERIALS, AHIDJO STRESSED REMUNERATIVE',\n",
        " 'PRICES, STABLIIZATION OF EXPORT EARNINGS, PROTECTION OF',\n",
        " 'PURCHASING POWER (WITH INDEXATION AS DESIRABLE MEANS),',\n",
        " 'REGULATORY MECHANISMS WITH COMMON FUND FINANCING, INCREASED',\n",
        " 'LOCAL PROCESSING AND BETTER MARKETS FOR EXPORTS OF BASIC',\n",
        " 'PRODUCTS.  RE DEVELOPMENT AND FINANCE, AHIDJO EXMPASIZED',\n",
        " 'INCREASED CAPITAL FLOWS (PUBLIC AND PRIVATE); INCREASED',\n",
        " 'COOPERATION BETWEEN SOURCES OF CAPITAL, RESOURCES AND',\n",
        " \"TECHNOLOGY; SPECIAL ASSISTANCE TO MSA'S; AND CONSULTATION\",\n",
        " 'AND COORDINATION FOR LONG-TERM, GRADUAL RESTRUCTURING OF',\n",
        " \"INTERNATIONAL DIVISION OF LABOR.  AHIDJO'S COMMENTS WERE\",\n",
        " 'MODERATE IN TONE BUT FULLY IN LINE WITH THIRD WORLD',\n",
        " 'POSIIONS.  END SUMMARY.',\n",
        " '',\n",
        " '2.  LOCAL PRESS ON FEBRUARY 7 PRINTED TEXT OF \"INTERVIEW\"',\n",
        " 'IN WHICH PRESIDENT AHIDJO RESPONDED TO QUESTIONS CONCERNING',\n",
        " 'CIEC.  SINCE IT APPEARS THAT QUESTIONS WERE SUBMITTED IN',\n",
        " \"ADVANCE AND WRITTEN ANSWERS PREPARED, PRESIDENT'S REPLIES\",\n",
        " \"REPRESENT CAREFULLY FORMULATED PRESENTATION OF GURC'S\",\n",
        " 'VIEWS.  CAMEROON IS MEMBER OF COMMISSIONS ON RAW MATERIALS',\n",
        " \"AND DEVELOPMENT, AND HAS SUPPLIED LDC'S DEPUTY EXECUTIVE\",\n",
        " 'SECRETARY OF CONFERENCE (AMBROISE FOALEM).',\n",
        " '',\n",
        " \"3.  IN RESPONSE TO FIRST QUESTION CONCERNING CAMEROON'S\",\n",
        " 'ROL IN CIEC, AHIDJO STATED THAT CAMEROON MUST DEFEND',\n",
        " 'NOT ONLY ITS OWN NATIONAL INTERESTS BUT THOSE OF THAT',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'PAGE 03  YAOUND 00572  01 OF 02  131742Z',\n",
        " '',\n",
        " 'CATEGORY OF STATES WHICH, BECAUSE OF CONSTANT DETERIORATION',\n",
        " 'IN THEIR TERMS OF TRADE, ANACHRONISTIC INTERNATIONAL',\n",
        " 'DIVISION OF LABOR AND INSUFFICIENT FLOW OF CAPITAL, FEED',\n",
        " 'WORLD GROWTH WITHOUT PARTICIPATING IN IT.  HE EXPRESSED',\n",
        " 'PRIDE THAT CAMEROON HAD BEEN CHOSEN TO SUPPLY DEPUTY EXECUTIVE',\n",
        " 'SECRETARY WHICH HE SAW AS MARK OF ESTEEM FOR ITS FOREIGN',\n",
        " 'POLICY BASED ON DIALOGUE, CONSULTATION AND TOLERANCE.',\n",
        " '',\n",
        " '4.  ASKED WHETHER ABSENCE OF SOCIALIST COUNTRIES FROM',\n",
        " 'CIEC WOULD HURT ADVENT OF NEW INTERNATIONAL ECONOMIC',\n",
        " 'ORDER (NIEO), AHIDJO LABELLED ABSENCE OF THOSE COUNTRIES',\n",
        " \"AS REGRETTABLE.  NOTING THEIR ABSTENTION ALSO FROM UN'S\",\n",
        " 'SECOND DEVELOPMENT DECADE, HE EXPRESSED RESPECT FOR THEIR',\n",
        " 'REASONS ADVANCED AS SOVEREIGN COUNTRIES, BUT REMAINED',\n",
        " 'CONVINCED THAT BETTER FUTURE FOR INTERNATIONAL COMMUNITY',\n",
        " 'MORE FEASIBLE IF CONSTRUCTED WITH RIGHTS AND OBLIGATIONS',\n",
        " 'FOR ALL.',\n",
        " '',\n",
        " '5.  ASKED WHAT POSITION CAMEROON WOULD TAKE CONCERNING',\n",
        " 'ENERGY CRISIS CONSIDERING ITS POSITION AS PETROLEUM',\n",
        " 'IMPORTER, AHIDJO COMMENTED THAT IT WAS DUE TO PETROLEUM',\n",
        " 'THAT NORTH-SOUTH DIALOGUE WAS ORGANIZED AND EXPRESSED',\n",
        " 'GRATITUDE TO OIL PRODUCING COUNTRIES FOR USING THEIR',\n",
        " 'BARGAINING POWER TO OBTAIN BROAD CONSULTATION ON WORLD',\n",
        " 'ECONOMIC PROBLEMS.  BUT STRUCTURE OF CIEC INDICATED THAT',\n",
        " 'PETROLEUM WOULD NOT BE SINGLE FOCAL POINT.  DUE TO PRICE',\n",
        " 'INCEASE OF PETROLEUM PRODUCTS AS WELL AS GENERAL',\n",
        " \"INFLATION, CAMEROON'S BALANCE OF PAYMENTS HAD BEEN SERIOUSLY\",\n",
        " 'AFFECTED.  CIEC MUST FIND WAY TO PROTECT PURCHASING POWER',\n",
        " 'OF ALL PRIMARY MATERIALS PRODUCERS, INCLUDING PETROLEUM',\n",
        " 'PRODUCERS.  AT SAME TIME, CIEC MUST SEEK MEANS TO DEVELOP',\n",
        " 'OTHER SOURCES OF ENERGY (SOLAR, HYDROELECTRIC, ETC) AND',\n",
        " 'DEVOTE ATTENTION TO PROBLEM OF ASSURED SUPPLIES WHICH',\n",
        " 'ESSENTIAL TO PETROLEUM CONSUMING COUNTRIES.  SUMMARIZING',\n",
        " 'HIS ANSWER, AHIDJO STATED THAT SAFEGUARDING PURCHASING POWER',\n",
        " 'OF EXPORT RECEIPTS, ESTABLISHING INTERNATIONAL COOPERATION FOR',\n",
        " \"DIVERSIFICATION OF ENERGY SOURCES, PROVIDING AID TO MSA'S,\",\n",
        " 'AND ASSURING SOURCES OF SUPPLY WERE SOME OF MAJOR CIEC GOALS.',\n",
        " '',\n",
        " '6.  RE HIS CONCEPTION OF NIEO, AHIDJO STRESSED NEED TO',\n",
        " 'ORGANIZE NEW INTERNATIONAL DIVISION OF LABOR WHICH WOULD',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'PAGE 04  YAOUND 00572  01 OF 02  131742Z',\n",
        " '',\n",
        " 'NECESSITATE STRUCTURAL READJUSTMENTS IN EUROPE AND NORTH',\n",
        " 'AMERICA AND REDEPLOYMENT OF PRODUCTION AND SERVICES',\n",
        " 'TO SOUTHERN HEMISPHERE.  SAW THIS AS LONG-TERM WORK',\n",
        " 'DEPENDENT ON CONTINUOUS CONSULTATION AND MUTUAL AWARENESS',\n",
        " 'OF INTERESTS.  NOT A QUESTION OF ABRUPT RUPTURE, OF',\n",
        " 'DISORGANIZING SOCIAL BALANCE IN DEVELOPED COUNTRIES.  BETTER',\n",
        " 'TO ENCOURAGE JOINT ENTERPRISES ASSOCIATING NATURAL AND',\n",
        " 'HUMAN RESOURCES WITH CAPITAL, TEHCNOLOGY AND INTERNATIONAL',\n",
        " \"COMMERICAL NETWORKS.  THIS WOULD PROVIDE DC'S WITH\",\n",
        " \"ASSURED SOURCES OF SUPPLY; LDC'S WITH INDUSTRIALIZATION, BETTER\",\n",
        " 'MEANS OF TRANSPORT AND IMPROVED MARKETS FOR THEIR PRODUCTS.',\n",
        " '',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " '',\n",
        " '',\n",
        " '',\n",
        " 'NNN',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'PAGE 01  YAOUND 00572  02 OF 02  131757Z',\n",
        " '',\n",
        " '42',\n",
        " 'ACTION EB-07',\n",
        " '',\n",
        " 'INFO  OCT-01  AF-06  ARA-06  EUR-12  EA-07  NEA-10  ISO-00  OIC-02',\n",
        " '',\n",
        " '      IO-11  ERDA-05  AID-05  CEA-01  CIAE-00  CIEP-01  COME-00',\n",
        " '',\n",
        " '      DODE-00  FEAE-00  FPC-01  H-02  INR-07  INT-05  L-03',\n",
        " '',\n",
        " '      NSAE-00  NSC-05  OMB-01  PM-04  USIA-06  SAM-01  OES-03',\n",
        " '',\n",
        " '      SP-02  SS-15  STR-04  TRSE-00  PA-01  PRS-01  OPIC-03  XMB-02',\n",
        " '',\n",
        " '      IGA-02  DOTE-00  AGR-05  /147 W',\n",
        " '                       ---------------------     076477',\n",
        " 'R 131630Z FEB 76',\n",
        " 'FM AMEMBASSY YAOUNDE',\n",
        " 'TO SECSTATE WASHDC 7792',\n",
        " 'INFO AMEMBASSY ALGIERS',\n",
        " 'AMEMBASSY BELGRADE',\n",
        " 'AMEMBASSY BRASILIA',\n",
        " 'AMEMBASSY BUENOS AIRES',\n",
        " 'AMEMBASSY CAIRO',\n",
        " 'AMEMBASSY CARACAS',\n",
        " 'AMEMBASSY JAKARTA',\n",
        " 'AMEMBASSY ISLAMABAD',\n",
        " 'AMEMBASSY JIDDA',\n",
        " 'AMEMBASSY KINGSTON',\n",
        " 'AMEMBASSY KINSHASA',\n",
        " 'AMEMBASSY LAGOS',\n",
        " 'AMEMBASSY LIMA',\n",
        " 'AMEMBASSY LUSAKA',\n",
        " 'AMEMBASSY MEXICO',\n",
        " 'AMEMBASSY NEW DELHI',\n",
        " 'AMEMBASSY PARIS',\n",
        " 'USMISSION USUN',\n",
        " 'AMCONSUL DOUALA',\n",
        " '',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE SECTION 2 OF 2 YAOUNDE 0572',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'PAGE 02  YAOUND 00572  02 OF 02  131757Z',\n",
        " '',\n",
        " 'PARIS FOR CIEC DELEGATION',\n",
        " '',\n",
        " 'AHIDJO THEN LISTED FOUR POINTS WHICH COULD SERVE AS BASIS',\n",
        " 'FOR DISCUSSIONS:  (A) ESTABLISHMENT OF REMUNERATIVE PRICES',\n",
        " 'FOR BASIS PRODUCTS AND STABILIZATION OF EXPORT EARNINGS,',\n",
        " 'WITH INDEXATION OF BASIC PRODUCT PRICES ON PRICES OF',\n",
        " 'IMPORTED GOODS DESIRABLE (SOUHAITABLE); (B) CREATION',\n",
        " 'OF INTERNATIONAL MECHANISMS FOR STOCKING AND REGULATING',\n",
        " 'LARGE VARIETY OF PRIMARY PRODUCTS AND CREATION OF COMMON',\n",
        " 'FUND FOR FINANCING THESE MECHANISMS; (C) ADOPTION OF',\n",
        " 'MEASURES TO ACCELERATE PROCESSING INDUSTRIES IN PRIMARY',\n",
        " 'PRODUCT PRODUCER STATES; (D) ADOPTION OF MEASURES TO',\n",
        " 'ELIMINATE CERTAIN OBSTACLES TO EXPORTATION OF BASIC PRODUCTS',\n",
        " '(DIRECT AND INDIRECT TAXATION, MIDDLEMEN BETWEEN PRODUCERS',\n",
        " 'AND FACTORIES, ETC).  AHIDJO ALSO CALLED FOR MEASURES',\n",
        " \"TO INTENSIFY FLOW OF CAPITAL TO LDC'S, IE, PUBLIC AND\",\n",
        " 'PRIVATE INVESTMENT, ACCESS TO CAPITAL MARKETS, AND REFORM',\n",
        " 'OF INTERNATIONAL MONETARY SYSTEM.  FINALLY, HE ADVOCATED',\n",
        " 'SPECIAL EMPHASIS ON POOR AFRICAN COUNTRIES DIS-',\n",
        " 'ADVANTAGED BY LACK OF TRANSPORT AND COMMUNICATIONS',\n",
        " 'INFRASTRUCTURE, LANDLOCKED COUNTRIES, AND THOSE SUFFEREING',\n",
        " 'FROM NATURAL DISASTERS SUCH AS DROUGHT.',\n",
        " '',\n",
        " '7.  ASKED ABOUT POSSIBILITY OF DIALOGUE BETWEEN OPEC AND',\n",
        " \"POOR LDC'S COMPLEMENTARY TO NORTH-SOUTH DIALOGUE,\",\n",
        " 'AHIDJO STATED THAT CAMEROON MUST BASICALLY RELY ON ITSELF',\n",
        " 'FOR DEVELOPMENT.  DEVELOPMENT MUST BE BY CAMEROONIANS,',\n",
        " \"FOR CAMEROONIANS, USING ALL OF COUNTRY'S RESOURCES, HUMAN\",\n",
        " 'AND MATERIAL.  EXTERNAL ASSISTANCE WAS ONLY SUPPLEMENT',\n",
        " 'TO SELF-DEVELOPMENT.  SOLIDARITY WITH THIRD WORLD WAS',\n",
        " 'ACTIVE POLICY AND COULD LEAD TO INCREASED HORIZONTAL',\n",
        " 'DIALOGUE (IE WITH PETROLEUM PRODUCERS)',\n",
        " 'AND/OR TO INCREASED MULTILATERAL ACTIONS INTEGRATING NATURAL',\n",
        " 'RESOURCES, TECHNOLOGIES AND CAPITAL OF VAIOUS COUNTRIES.',\n",
        " 'RECENT DECISIONS TAKEN BY OPEC AT PARIS TO THIS EFFECT',\n",
        " 'WERE SIGNIFICANT.',\n",
        " '',\n",
        " '8.  IN FINAL COMMENT, AHIDJO STATED FIALURE AT CIEC',\n",
        " 'WOULD BE DISASTER NOW AND FOR YEARS TO COME.  HE SAID',\n",
        " 'THAT, IN EFFECT, CIEC PARTICIPANTS WERE CONDEMNED TO',\n",
        " 'SUCCEED.',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " 'PAGE 03  YAOUND 00572  02 OF 02  131757Z',\n",
        " '',\n",
        " '',\n",
        " '9.  GENERAL COMMENT:  CAMEROON FUNDAMENTALLY BELIEVES IN',\n",
        " 'OUA AND NON-ALIGNED PHILOSOPHY OF STRENGTH THROUGH UNITY.',\n",
        " 'ITS CONSTANT ADHERENCE TO THIRD WORLD POSITIONS',\n",
        " 'WHILE NOT AGGRESSIVELY SEEKING ANY LEADERSHIP ROLE REFLECTS',\n",
        " 'ITS APPARENT BELIEF THAT COORDINATED THIRD WORLD',\n",
        " 'POLITICAL ACTION IS NEEEDED TO OBTAIN ECONOMIC GOAL OF',\n",
        " \"DEVELOPMENT.  TO SAY THAT CAMEROON AND OTHER LDC'S ACT\",\n",
        " 'CONTRARY, IN PARTICULAR CASES, TO THEIR BEST INTERESTS',\n",
        " 'MISSES THE BASIC POINT.  AS AHIDJO POINTED OUT, WHILE',\n",
        " 'INCREASED OIL PRICES MIGHT HAVE HURT LDC CONSUMERS,',\n",
        " 'THIS MOVE BROUGHT POWER FOR ATTAINMENT',\n",
        " 'OF THEIR LONG-TERM GOAL -- DEVELOPMENT.  ON THE OTHER',\n",
        " 'HAND, DEVELOPMENT, IN CAMEROON, MEANS WORKING WITH EUROPE',\n",
        " 'AND NORTH AMERICA AND OBTAINING WHAT THEY HAVE TO OFFER.',\n",
        " 'THEREFORE GURC HAS NO DESIRE TO GET INTO SITUATION',\n",
        " 'OF CONFRONTATION, AS FINANCE MINISTER YONDO ALSO',\n",
        " 'EMPHASIZED IN RECENT CONVERSATION WITH AMBASSADOR.',\n",
        " 'CAMEROON TAKES ITS ROLE IN CIEC SERIOUSLY AND HAS SENT',\n",
        " 'ITS BEST MEN TO THE CONFERENCE.  LIKEWISE, IT WILL TO',\n",
        " 'BEST OF ITS ABILITY DEFEND INTERESTS OF OTHER AFRICAN STATES',\n",
        " 'NOT REPRESENTED.  IN SUMMARY, CAMEROON CAN BE EXPECTED',\n",
        " 'TO WORK CONSTRUCTIVELY IN CIEC WITHOUT ABANDONING BASIC',\n",
        " 'POSITIONS ON WHICH THIRD WORLD UNITY IS BASED.',\n",
        " 'SPIRO',\n",
        " '',\n",
        " '',\n",
        " 'LIMITED OFFICIAL USE',\n",
        " '',\n",
        " '',\n",
        " '',\n",
        " '',\n",
        " 'NNN']"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "* Now since our end goal is to build a topic model we probably want to have a more fexible streamer, i.e. one that can return file ids, text or tokens (based on some predefined tokenizer)\n",
      "    * luckily we have one such streamer written"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from rosetta import TextFileStreamer, TokenizerBasic\n",
      "text_streamer = TextFileStreamer(text_base_path=CABLES, file_type='*', \n",
      "                                           tokenizer=TokenizerBasic())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stream = text_streamer.info_stream()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "stream.next()\n",
      "# this is a dictionary"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "{'cached_path': './data\\\\1976ZAGREB00538',\n",
        " 'doc_id': '1976ZAGREB00538',\n",
        " 'text': 'MRN: 1976ZAGREB000538  SEGMENT NUMBER: 000001  EXPAND ERROR ENCOUNTERED;\\nTELEGRAM TEXT FOR THIS SEGMENT IS UNAVAILABLE',\n",
        " 'tokens': ['mrn',\n",
        "  'segment',\n",
        "  'number',\n",
        "  'expand',\n",
        "  'error',\n",
        "  'encountered',\n",
        "  'telegram',\n",
        "  'text',\n",
        "  'segment',\n",
        "  'unavailable']}"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stream.next()['tokens']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "['unclassified',\n",
        " 'poss',\n",
        " 'dupe',\n",
        " 'page',\n",
        " 'zurich',\n",
        " 'action',\n",
        " 'info',\n",
        " 'apr',\n",
        " 'fm',\n",
        " 'amconsul',\n",
        " 'zurich',\n",
        " 'secstate',\n",
        " 'washdc',\n",
        " 'info',\n",
        " 'amembassy',\n",
        " 'bern',\n",
        " 'unclas',\n",
        " 'zurich',\n",
        " 'tags',\n",
        " 'afsp',\n",
        " 'sz',\n",
        " 'subj',\n",
        " 'transfer',\n",
        " 'office',\n",
        " 'ref',\n",
        " 'zurich',\n",
        " 'assumed',\n",
        " 'charge',\n",
        " 'april',\n",
        " 'consul',\n",
        " 'james',\n",
        " 'huffman',\n",
        " 'hayden',\n",
        " 'unclassified',\n",
        " 'nnn']"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lets take a quick look at TextFileStreamer\n",
      "TextFileStreamer?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# a tokenizer function is just a one that takes a string and returns a list of strings.\n",
      "# for disambiguation you need to write your own function that can use regex."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* Note: you can pass a tokenizer function to TextFileStreamer(), i.e. any function that takes a string of text and returns a list of strings (the \"tokens\")\n",
      "    * We have written a basic tokenizer function and class to add functionality and because the nltk.word_tokenize() was slow\n",
      "* It also has a few other nice options such as shuffle, file_type, etc and a bunch of methods"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = stream.next()['text']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "text_streamer.tokenizer.text_to_token_list(text)\n",
      "#text_streamer.tokenizer.text_to_counter(text)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lets look at a few methods\n",
      "token_stream = text_streamer.token_stream() # returns a generator function which yields a stream of tokens"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "token_stream.next() # this is what our basic tokenizer returns (we are skipping stop words and numerics by default)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "['unclassified',\n",
        " 'page',\n",
        " 'zagreb',\n",
        " 'action',\n",
        " 'info',\n",
        " 'jul',\n",
        " 'fm',\n",
        " 'amconsul',\n",
        " 'zagreb',\n",
        " 'secstate',\n",
        " 'washdc',\n",
        " 'immediate',\n",
        " 'info',\n",
        " 'amembassy',\n",
        " 'belgrade',\n",
        " 'unclas',\n",
        " 'zagreb',\n",
        " 'tags',\n",
        " 'scul',\n",
        " 'yo',\n",
        " 'subject',\n",
        " 'message',\n",
        " 'dr',\n",
        " 'margan',\n",
        " 'dr',\n",
        " 'fletcher',\n",
        " 'ref',\n",
        " 'state',\n",
        " 'notal',\n",
        " 'reftel',\n",
        " 'arrived',\n",
        " 'dr',\n",
        " 'margan',\n",
        " 'departed',\n",
        " 'monday',\n",
        " 'july',\n",
        " \"margan's\",\n",
        " 'office',\n",
        " 'suggests',\n",
        " 'dr',\n",
        " 'fletcher',\n",
        " 'reach',\n",
        " 'through',\n",
        " 'yugoslav',\n",
        " 'embassy',\n",
        " 'washington',\n",
        " 'kaiser',\n",
        " 'unclassified',\n",
        " 'nnn']"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "text_streamer.doc_id # returns a list of retrieved doc ids etc \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#if you want to use another tokenizer it's easy\n",
      "import nltk\n",
      "nltk.word_tokenize(text)\n",
      "text_streamer_nltk = TextFileStreamer(text_base_path=CABLES, file_type='*', \n",
      "                                      tokenizer_func=nltk.word_tokenize)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stream_nltk = text_streamer_nltk.token_stream()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stream_nltk.next()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "['UNCLASSIFIED',\n",
        " 'PAGE',\n",
        " '01',\n",
        " 'ZAGREB',\n",
        " '00803',\n",
        " '201505Z',\n",
        " '71',\n",
        " 'ACTION',\n",
        " 'COME-00',\n",
        " 'INFO',\n",
        " 'OCT-01',\n",
        " 'EUR-12',\n",
        " 'ISO-00',\n",
        " 'EB-07',\n",
        " 'PRS-01',\n",
        " '/021',\n",
        " 'W',\n",
        " '--',\n",
        " '--',\n",
        " '--',\n",
        " '--',\n",
        " '--',\n",
        " '--',\n",
        " '--',\n",
        " '--',\n",
        " '--',\n",
        " '--',\n",
        " '-',\n",
        " '099482',\n",
        " 'R',\n",
        " '171540Z',\n",
        " 'SEP',\n",
        " '76',\n",
        " 'FM',\n",
        " 'AMCONSUL',\n",
        " 'ZAGREB',\n",
        " 'TO',\n",
        " 'SECSTATE',\n",
        " 'WASHDC',\n",
        " '4011',\n",
        " 'INFO',\n",
        " 'AMEMBASSY',\n",
        " 'THE',\n",
        " 'HAGUE',\n",
        " 'AMEMBASSY',\n",
        " 'PARIS',\n",
        " 'AMEMBASSY',\n",
        " 'BELGRADE',\n",
        " 'UNCLAS',\n",
        " 'ZAGREB',\n",
        " '803',\n",
        " 'EO',\n",
        " '11652',\n",
        " 'NA',\n",
        " 'TAGS',\n",
        " ':',\n",
        " 'BENC',\n",
        " 'YO',\n",
        " 'SUBJ',\n",
        " ':',\n",
        " 'SLOVENE',\n",
        " 'GAS',\n",
        " 'PIPELINE',\n",
        " 'CONTRACT',\n",
        " 'SIGNED',\n",
        " 'REF',\n",
        " ':',\n",
        " 'ZAGREB',\n",
        " '691',\n",
        " '(',\n",
        " 'NOTAL',\n",
        " ')',\n",
        " '1.',\n",
        " 'SEPTEMBER',\n",
        " '17',\n",
        " '``',\n",
        " 'DELO',\n",
        " \"''\",\n",
        " 'REPORTS',\n",
        " 'THAT',\n",
        " 'REPRESENTATIVES',\n",
        " 'OF',\n",
        " 'PETROL',\n",
        " '(',\n",
        " 'TOZD',\n",
        " 'FOR',\n",
        " 'NATURAL',\n",
        " 'GAS',\n",
        " ')',\n",
        " 'AND',\n",
        " 'JOINT',\n",
        " 'VENTURE',\n",
        " 'OF',\n",
        " 'SPIE',\n",
        " 'BATTIGNOLLES',\n",
        " '(',\n",
        " 'FRENCH',\n",
        " ')',\n",
        " 'AND',\n",
        " 'NACAP',\n",
        " '(',\n",
        " 'DUTCH',\n",
        " ')',\n",
        " 'SIGNED',\n",
        " 'GENERAL',\n",
        " 'CONSTRUCTION',\n",
        " 'CONTRACT',\n",
        " 'FOR',\n",
        " 'SLOVENE',\n",
        " 'GAS',\n",
        " 'PIPELINE',\n",
        " 'IN',\n",
        " 'LJUBLJANA',\n",
        " 'SEPTEMBER',\n",
        " '16.',\n",
        " '``',\n",
        " 'DELO',\n",
        " \"''\",\n",
        " 'NOTES',\n",
        " 'THAT',\n",
        " 'CONTRACT',\n",
        " 'WILL',\n",
        " 'BECOME',\n",
        " 'EFFECTIVE',\n",
        " 'UPON',\n",
        " 'REGISTRATION',\n",
        " 'BY',\n",
        " 'APPROPRIATE',\n",
        " 'FEDERAL',\n",
        " 'AUTHORITIES.',\n",
        " '2.',\n",
        " 'ARTICLE',\n",
        " 'ALSO',\n",
        " 'NOTES',\n",
        " 'THAT',\n",
        " 'SIGNING',\n",
        " 'TOOK',\n",
        " 'PLACE',\n",
        " 'IN',\n",
        " 'PRESENCE',\n",
        " 'OF',\n",
        " 'REPRESENTATIVES',\n",
        " 'OF',\n",
        " 'ENTERPRISES',\n",
        " 'WHICH',\n",
        " 'WILL',\n",
        " 'PARTICIPATE',\n",
        " 'IN',\n",
        " 'SUPPLYING',\n",
        " 'SOME',\n",
        " 'OF',\n",
        " 'EQUIPMENT',\n",
        " 'USED',\n",
        " 'IN',\n",
        " 'PIPELINE',\n",
        " 'CONSTRUCTION.',\n",
        " 'INCLUDED',\n",
        " 'WERE',\n",
        " 'TEHNIKA',\n",
        " ',',\n",
        " 'LJUBLJANA',\n",
        " ';',\n",
        " 'IMP',\n",
        " ',',\n",
        " 'LJUBLJANA',\n",
        " ';',\n",
        " 'ZP',\n",
        " 'ISKRA',\n",
        " ',',\n",
        " 'LJUBLJANA',\n",
        " ';',\n",
        " 'HIDROMONTAZA',\n",
        " ',',\n",
        " 'MARIBOR',\n",
        " ';',\n",
        " 'AND',\n",
        " 'JUVENT',\n",
        " ',',\n",
        " 'ZAGREB.',\n",
        " 'KAISER',\n",
        " 'UNCLASSIFIED',\n",
        " 'NNN']"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Gensim LDA Topic Modeling\n",
      "* LDA = Latent Dirichlet Allocation \n",
      "    * treats each document as a bag of words \n",
      "    * a topic is chosen from a topic distribution $p(k)$ where $k=1, \\dots , K$\n",
      "    * a word is chosen from the k'th topic distribution $p(w|k)$ and thrown into the bag\n",
      "    * distrubutions $p(k)$ depends on $\\theta$ ~ $Dir(\\alpha)$ and $p(w|k)$ depends on $\\beta$ a $k\\times V$ matrix of word probabilties\n",
      "        * these 'latent' variables are chosen to maximize the probability of producing the observed documents, and in turn depend on user chosen parameters $\\alpha$ and $\\eta$ \n",
      "    * the model produces two important probability distributions:\n",
      "        * $p(w|k)$, the probability of $w$ bring generated by topic $k$ and\n",
      "        * $p(k|d)$, the probabilty of topic $k$ being used to generate a randomly chosen word from document $d$ \n",
      "    * these topic and word weights can be used to understand the semantic structure of the documents as well as generate document feature\n",
      "    * for more details about LDA topic modeling see the wonderful Blei, Ng, and Jordan [paper](http://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf)\n",
      "* Gensim there are essentially three important objects you work with\n",
      "    * dictionary (of all important words in the corpus and their hash value)\n",
      "    * corpus (sparse vector representation of each dictionary)\n",
      "    * for more information see http://radimrehurek.com/gensim/\n",
      "    \n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#you will probably need to install gensim \n",
      "#run \"pip install gensim\" if you have pip... \n",
      "import rosetta.workflow.topic_seek as ts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "basic_tokenizer = TokenizerBasic()\n",
      "T = ts.Topics(text_base_path=CABLES, file_type='*', tokenizer=basic_tokenizer, limit=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#make the gensim dictionary\n",
      "T.set_dictionary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#dictionary stores hash map values for the words, or \"tokenids\"\n",
      "T.dictionary.items()[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "[(0, 'niact'),\n",
        " (1, 'limited'),\n",
        " (2, 'gds'),\n",
        " (3, 'protocol'),\n",
        " (4, 'office'),\n",
        " (5, 'ambassador'),\n",
        " (6, 'being'),\n",
        " (7, 'telegram'),\n",
        " (8, 'meetings'),\n",
        " (9, 'mission')]"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(T.dictionary.items())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "271"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lets do a little eda\n",
      "id2token = dict(T.dictionary.items())  # dictionary.id2token is not populated by default!!!\n",
      "words = pd.DataFrame(\n",
      "                {id2token[tokenid]: [tokenid, docfreq] \n",
      "                 for tokenid, docfreq in T.dictionary.dfs.iteritems()},\n",
      "                index=['tokenid', 'docfreq']).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "print words.head(50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "              tokenid  docfreq\n",
        "above              93        6\n",
        "additional        149        7\n",
        "address           110        5\n",
        "advise            229        7\n",
        "africa            138        5\n",
        "afsp               36        9\n",
        "again             212        5\n",
        "against           120        5\n",
        "already           132        8\n",
        "ambassador          5        8\n",
        "amconsul           87       50\n",
        "american          124       10\n",
        "apparently        210        5\n",
        "appreciate         96       14\n",
        "apr               135       10\n",
        "april             123        8\n",
        "arrival            98        6\n",
        "article           111        6\n",
        "asap              102        6\n",
        "asked             241        5\n",
        "assistance        268        5\n",
        "assistant          43        6\n",
        "aug                23       10\n",
        "august            100        9\n",
        "authorities       142       10\n",
        "aware             172        5\n",
        "bank               54        7\n",
        "before            151        9\n",
        "being               6        5\n",
        "belgrade           70       24\n",
        "bern              179        9\n",
        "bexp              116        6\n",
        "cameroon          231       15\n",
        "cameroonian        20        8\n",
        "case              183        7\n",
        "charge             30       11\n",
        "chief             262        7\n",
        "cm                133       28\n",
        "comment           130        9\n",
        "commercial        104        8\n",
        "concerning        169        5\n",
        "conference        147        5\n",
        "confidential       40       11\n",
        "confirmation      206        5\n",
        "congen             33        6\n",
        "connection        219        5\n",
        "consul             61        9\n",
        "consulate         181        5\n",
        "contact           221        7\n",
        "continue           62        5\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Log plot of distribution shows rapidly decaying tail\n",
      "words.docfreq.apply(np.log10).hist(bins=200)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "<matplotlib.axes.AxesSubplot at 0x134e7400>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEACAYAAABBDJb9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQM1cRMQAauYiIgb4P4K2DFOiosxvAAAAAElFTkSuQmCC\n",
       "text": [
        "<matplotlib.figure.Figure at 0x134e7d68>"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " Volume in drive C is TI106049W0B\n",
        " Volume Serial Number is 523A-1659\n",
        "\n",
        " Directory of C:\\Users\\AJ\\PyDataNYC2013\\GenSimTalk\n",
        "\n",
        "11/10/2013  02:11 PM    <DIR>          .\n",
        "11/10/2013  02:11 PM    <DIR>          ..\n",
        "11/10/2013  01:29 PM    <DIR>          data\n",
        "11/10/2013  01:29 PM            55,164 PyData_NYC_2013-org.ipynb\n",
        "11/10/2013  02:11 PM    <DIR>          tmp\n",
        "               1 File(s)         55,164 bytes\n",
        "               4 Dir(s)  325,325,840,384 bytes free\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Lets build the gensim corpus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#T.set_corpus(serialize_path='/tmp/my_corpus') \n",
      "T.set_corpus(serialize_path='tmp') \n",
      "#Note: since building a corpus with gensim can be time consuming we require you provide a save path; \n",
      "#of course, this is not strictly necessary from within gensim"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 13] Permission denied: 'tmp'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-53-2e5f6f8631f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#T.set_corpus(serialize_path='/tmp/my_corpus')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserialize_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tmp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#Note: since building a corpus with gensim can be time consuming we require you provide a save path;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#of course, this is not strictly necessary from within gensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\rosetta\\workflow\\topic_seek.pyc\u001b[0m in \u001b[0;36mset_corpus\u001b[1;34m(self, load_path, serialize_path, doc_id)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             self.corpus = gensim_helpers.SvmLightPlusCorpus.from_streamer_dict(\n\u001b[1;32m--> 120\u001b[1;33m                 self.streamer, self.dictionary, serialize_path, doc_id=doc_id)\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[0mbuild_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m3600.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_print\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Corpus built %.2f hours'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbuild_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\rosetta\\text\\gensim_helpers.pyc\u001b[0m in \u001b[0;36mfrom_streamer_dict\u001b[1;34m(self, streamer, dictionary, fname, doc_id, limit)\u001b[0m\n\u001b[0;32m    176\u001b[0m         streamer_corpus = StreamerCorpus(\n\u001b[0;32m    177\u001b[0m             streamer, dictionary, doc_id=doc_id, limit=limit)\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mstreamer_corpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mSvmLightPlusCorpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\rosetta\\text\\gensim_helpers.pyc\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \"\"\"\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Make the corpus and .index file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mcorpora\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSvmLightCorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# Make the .doc_id file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gensim\\corpora\\indexedcorpus.pyc\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(serializer, fname, corpus, id2word, index_fname, progress_cnt, labels)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[0moffsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserializer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m                 \u001b[0moffsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserializer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moffsets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\gensim\\corpora\\svmlightcorpus.pyc\u001b[0m in \u001b[0;36msave_corpus\u001b[1;34m(fname, corpus, id2word, labels)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0moffsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdocno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdocno\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;31m# target class is 0 by default\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIOError\u001b[0m: [Errno 13] Permission denied: 'tmp'"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lets look at the corpus\n",
      "T.corpus.doc_id_all[99], T.corpus.docbyoffset(0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'Topics' object has no attribute 'corpus'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-54-c5dacb3fb9ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#lets look at the corpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc_id_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m99\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocbyoffset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mAttributeError\u001b[0m: 'Topics' object has no attribute 'corpus'"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Lets build out first LDA topic model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "T.fit_lda(num_topics=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'Topics' object has no attribute 'corpus'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-55-fc2c88713f96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_lda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\rosetta\\workflow\\topic_seek.pyc\u001b[0m in \u001b[0;36mfit_lda\u001b[1;34m(self, num_topics, alpha, eta, passes, chunksize, update_every)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         lda = models.LdaModel(self.corpus, id2word=self.dictionary,\n\u001b[0m\u001b[0;32m    147\u001b[0m             \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             chunksize=chunksize, update_every=update_every)\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'Topics' object has no attribute 'corpus'"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#and lets look at our results\n",
      "T.write_topics()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "topic 0\n",
        "0.028*confidential + 0.026*yaounde + 0.019*africa + 0.017*department + 0.014*charge\n",
        "topic 1\n",
        "0.091*zagreb + 0.027*amconsul + 0.023*february + 0.022*subject + 0.020*yo\n",
        "topic 2\n",
        "0.047*segment + 0.025*telegram + 0.024*mrn + 0.024*number + 0.024*text\n",
        "topic 3\n",
        "0.057*yaounde + 0.028*yaound + 0.015*official + 0.014*state + 0.013*africa\n",
        "topic 4\n",
        "0.043*zagreb + 0.029*yugoslav + 0.024*use + 0.024*limited + 0.020*official\n",
        "topic 5\n",
        "0.032*yaounde + 0.021*korean + 0.019*gurc + 0.017*official + 0.017*south\n",
        "topic 6\n",
        "0.059*zurich + 0.033*immediate + 0.027*africa + 0.023*mr + 0.020*united\n",
        "topic 7\n",
        "0.028*yaounde + 0.021*state + 0.020*confidential + 0.020*zurich + 0.019*zagreb\n",
        "topic 8\n",
        "0.033*zurich + 0.022*gurc + 0.017*amconsul + 0.017*subj + 0.016*zagreb\n",
        "topic 9\n",
        "0.063*zagreb + 0.027*official + 0.023*limited + 0.023*use + 0.020*belgrade\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Of course; there are many more things that can be done such as parameter tuning. \n",
      "\n",
      "* tune the topics param $\\alpha$, the word param $\\eta$, passes, chunksize, etc\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Also, for a much faster LDA implementation see [Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit/wiki)\n",
      "* Note: there is a DsPy python wrapper for VW which you can find [here](https://github.com/columbia-applied-data-science/dspy/tree/master/dspy/text)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Have fun!\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}