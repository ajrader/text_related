{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gensim demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from strings to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "              \"The EPS user interface management system\",\n",
    "              \"System and human system engineering testing of EPS\",\n",
    "              \"Relation of user perceived response time to error measurement\",\n",
    "              \"The generation of random binary unordered trees\",\n",
    "              \"The intersection graph of paths in trees\",\n",
    "              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "              \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tiny corpus of nine documents, each consisting of only a single sentence.\n",
    "\n",
    "\n",
    "First, let’s tokenize the documents, remove common words (using a toy stoplist) as well as words that only appear once in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove common words and tokenize\n",
    "stoplist = set('for a of the to in and'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'],\n",
      " ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'management', 'system'],\n",
      " ['system', 'human', 'system', 'engineering', 'testing', 'eps'],\n",
      " ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'],\n",
      " ['generation', 'random', 'binary', 'unordered', 'trees'],\n",
      " ['intersection', 'graph', 'paths', 'trees'],\n",
      " ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token]+=1\n",
    "    \n",
    "texts = [[token for token in text if frequency[token]>1] for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using bag-of-words approach:\n",
    "It is advantageous to represent the questions only by their (integer) ids. The mapping between questions and ids is called a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['graph', 'trees', 'computer', 'interface', 'human']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('/home/kesj/tmp/deerwester.dict') #store this dictionary for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'graph': 10, 'trees': 9, 'computer': 1, 'interface': 0, 'human': 2, 'survey': 4, 'time': 7, 'minors': 11, 'response': 3, 'user': 6, 'system': 5, 'eps': 8}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates an n-dimensional vector where $n$ is the number of words in my corporus.\n",
    "here $n$ = 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (2, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)],\n",
      " [(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
      " [(0, 1), (5, 1), (6, 1), (8, 1)],\n",
      " [(2, 1), (5, 2), (8, 1)],\n",
      " [(3, 1), (6, 1), (7, 1)],\n",
      " [(9, 1)],\n",
      " [(9, 1), (10, 1)],\n",
      " [(9, 1), (10, 1), (11, 1)],\n",
      " [(4, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('/home/kesj/tmp/deerwester.mm', corpus)\n",
    "pprint(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialize the *transformation* using TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.7071067811865476), (4, 0.7071067811865476)]\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus)\n",
    "vec = [(0,1),(4,1)]\n",
    "print(tfidf[vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.7071067811865476), (2, 0.7071067811865476)]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf[new_vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.40824828), (1, 0.31412902), (2, 0.40376222), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.44424552)]\n"
     ]
    }
   ],
   "source": [
    "sims=index[tfidf[vec]]\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Streaming -- One Document at a Time\n",
    "Note that _corpus_ above resides fully in memory, as a plain Python list. In this simple example, it doesn’t matter much, but just to make things clear, let’s assume there are millions of documents in the corpus. Storing all of them in RAM won’t do. Instead, let’s assume the documents are stored in a file on disk, one document per line. Gensim only requires that a corpus must be able to return one document vector at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for line in open('/san-data/shared/kesj/mycorpus.txt'):\n",
    "            # assume there is one document per line, tokens separated by whitespace\n",
    "            yield dictionary.doc2bow(line.lower().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The assumption that each document occupies one line in a single file is not important; you can mold the `__iter__` function to fit your input format, whatever it is. Walking directories, parsing XML, accessing network... Just parse your input to retrieve a clean list of tokens in each document, then convert the tokens via a dictionary to their ids and yield the resulting sparse vector inside `__iter__`.\n",
    "\n",
    "#### Note I need to do this to parse the pandas dataframe text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_memory_friendly = MyCorpus() # doesn't load the corpus into memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyCorpus object at 0x7f6897bae908>\n"
     ]
    }
   ],
   "source": [
    "print(corpus_memory_friendly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corpus is now an object (without any defined print method) so `print` just outputs the address of the object in memory. This isn't very useful. To see the constituent vectors, iterate over the corpus and print each document vector (one at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n",
      "[(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(0, 1), (5, 1), (6, 1), (8, 1)]\n",
      "[(2, 1), (5, 2), (8, 1)]\n",
      "[(3, 1), (6, 1), (7, 1)]\n",
      "[(9, 1)]\n",
      "[(9, 1), (10, 1)]\n",
      "[(9, 1), (10, 1), (11, 1)]\n",
      "[(4, 1), (10, 1), (11, 1)]\n"
     ]
    }
   ],
   "source": [
    "for vector in corpus_memory_friendly: # load one vector into memor at a time\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to construct the dictionary without loading all texts into memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(line.lower().split() for line in open('/san-data/shared/kesj/mycorpus.txt'))\n",
    "# remove stop words and words that appear only once\n",
    "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist\n",
    "            if stopword in dictionary.token2id]\n",
    "#once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq == 1] works with python2.x\n",
    "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.items() if docfreq == 1] #works with python3.x\n",
    "dictionary.filter_tokens(stop_ids + once_ids) # remove stop words and words that appear only once\n",
    "dictionary.compactify() # remove gaps in id sequence after words that were removed\n",
    "pprint(len(dictionary.token2id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 10,\n",
       " 'eps': 11,\n",
       " 'graph': 2,\n",
       " 'human': 5,\n",
       " 'interface': 1,\n",
       " 'minors': 3,\n",
       " 'response': 8,\n",
       " 'survey': 6,\n",
       " 'system': 0,\n",
       " 'time': 7,\n",
       " 'trees': 4,\n",
       " 'user': 9}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## I want to look at the difference between using tfidf and idf for the lda part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "#plt.hist(tfidf.dfs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2, 1: 2, 2: 2, 3: 2, 4: 2, 5: 3, 6: 3, 7: 2, 8: 2, 9: 3, 10: 3, 11: 2}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.1699250014423126,\n",
       " 1: 2.1699250014423126,\n",
       " 2: 2.1699250014423126,\n",
       " 3: 2.1699250014423126,\n",
       " 4: 2.1699250014423126,\n",
       " 5: 1.5849625007211563,\n",
       " 6: 1.5849625007211563,\n",
       " 7: 2.1699250014423126,\n",
       " 8: 2.1699250014423126,\n",
       " 9: 1.5849625007211563,\n",
       " 10: 1.5849625007211563,\n",
       " 11: 2.1699250014423126}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skl_tfidfvect = TfidfVectorizer(stop_words=stoplist,min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \" \".join(\n",
    "#texts_str = \" \".join([line for line in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human machine interface for lab abc computer applications A survey of user opinion of computer system response time The EPS user interface management system System and human system engineering testing of EPS Relation of user perceived response time to error measurement The generation of random binary unordered trees The intersection graph of paths in trees Graph minors IV Widths of trees and well quasi ordering Graph minors A survey'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#texts_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a', 'and', 'for', 'in', 'of', 'the', 'to'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoplist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sklX= skl_tfidfvect.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'computer': 0,\n",
       "  'eps': 1,\n",
       "  'graph': 2,\n",
       "  'human': 3,\n",
       "  'interface': 4,\n",
       "  'minors': 5,\n",
       "  'response': 6,\n",
       "  'survey': 7,\n",
       "  'system': 8,\n",
       "  'time': 9,\n",
       "  'trees': 10,\n",
       "  'user': 11},\n",
       " {'computer': 10,\n",
       "  'eps': 11,\n",
       "  'graph': 2,\n",
       "  'human': 5,\n",
       "  'interface': 1,\n",
       "  'minors': 3,\n",
       "  'response': 8,\n",
       "  'survey': 6,\n",
       "  'system': 0,\n",
       "  'time': 7,\n",
       "  'trees': 4,\n",
       "  'user': 9})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_tfidfvect.vocabulary_, dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.57735027,  0.        ,  0.        ,  0.57735027,  0.57735027,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.42593857,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.42593857,  0.42593857,  0.37034129,  0.42593857,\n",
       "          0.        ,  0.37034129],\n",
       "        [ 0.        ,  0.53361154,  0.        ,  0.        ,  0.53361154,\n",
       "          0.        ,  0.        ,  0.        ,  0.46395983,  0.        ,\n",
       "          0.        ,  0.46395983],\n",
       "        [ 0.        ,  0.44614767,  0.        ,  0.44614767,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.77582505,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.6023681 ,  0.        ,  0.        ,  0.6023681 ,\n",
       "          0.        ,  0.52374168],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          1.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.70710678,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.70710678,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.54859115,  0.        ,  0.        ,\n",
       "          0.63094809,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.54859115,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.52374168,  0.        ,  0.        ,\n",
       "          0.6023681 ,  0.        ,  0.6023681 ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklX.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.2039728 ,  2.2039728 ,  1.91629073,  2.2039728 ,  2.2039728 ,\n",
       "         2.2039728 ,  2.2039728 ,  2.2039728 ,  1.91629073,  2.2039728 ,\n",
       "         1.91629073,  1.91629073]),\n",
       " {'computer': 0,\n",
       "  'eps': 1,\n",
       "  'graph': 2,\n",
       "  'human': 3,\n",
       "  'interface': 4,\n",
       "  'minors': 5,\n",
       "  'response': 6,\n",
       "  'survey': 7,\n",
       "  'system': 8,\n",
       "  'time': 9,\n",
       "  'trees': 10,\n",
       "  'user': 11})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_tfidfvect.idf_, skl_tfidfvect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(int,\n",
       "             {'computer': 2,\n",
       "              'eps': 2,\n",
       "              'graph': 3,\n",
       "              'human': 2,\n",
       "              'interface': 2,\n",
       "              'minors': 2,\n",
       "              'response': 2,\n",
       "              'survey': 2,\n",
       "              'system': 4,\n",
       "              'time': 2,\n",
       "              'trees': 3,\n",
       "              'user': 3}),\n",
       " 9)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_counts = defaultdict(int)\n",
    "for doc in texts:\n",
    "    for word in doc:\n",
    "        document_counts[word]+=1\n",
    "    \n",
    "document_counts, len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('graph', 1.3862943611198906),\n",
       " ('trees', 1.3862943611198906),\n",
       " ('computer', 1.7047480922384253),\n",
       " ('interface', 1.7047480922384253),\n",
       " ('human', 1.7047480922384253),\n",
       " ('survey', 1.7047480922384253),\n",
       " ('time', 1.7047480922384253),\n",
       " ('minors', 1.7047480922384253),\n",
       " ('response', 1.7047480922384253),\n",
       " ('user', 1.3862943611198906),\n",
       " ('system', 1.1786549963416462),\n",
       " ('eps', 1.7047480922384253)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "[(key,np.log(9/val+1) )for key,val in document_counts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2829802"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.166*1.7047"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('trees', 10), 0.25),\n",
       " (('minors', 5), 0.16666666666666666),\n",
       " (('human', 3), 0.16666666666666666),\n",
       " (('interface', 4), 0.16666666666666666),\n",
       " (('response', 6), 0.16666666666666666),\n",
       " (('user', 11), 0.25),\n",
       " (('system', 8), 0.3333333333333333),\n",
       " (('graph', 2), 0.25),\n",
       " (('time', 9), 0.16666666666666666),\n",
       " (('computer', 0), 0.16666666666666666),\n",
       " (('eps', 1), 0.16666666666666666),\n",
       " (('survey', 7), 0.16666666666666666)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(key,frequency[key[0]]/12) for key in skl_tfidfvect.vocabulary_.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.1699250014423126,\n",
       " 1: 2.1699250014423126,\n",
       " 2: 2.1699250014423126,\n",
       " 3: 2.1699250014423126,\n",
       " 4: 2.1699250014423126,\n",
       " 5: 1.5849625007211563,\n",
       " 6: 1.5849625007211563,\n",
       " 7: 2.1699250014423126,\n",
       " 8: 2.1699250014423126,\n",
       " 9: 1.5849625007211563,\n",
       " 10: 1.5849625007211563,\n",
       " 11: 2.1699250014423126}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.idfs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 10,\n",
       " 'eps': 11,\n",
       " 'graph': 2,\n",
       " 'human': 5,\n",
       " 'interface': 1,\n",
       " 'minors': 3,\n",
       " 'response': 8,\n",
       " 'survey': 6,\n",
       " 'system': 0,\n",
       " 'time': 7,\n",
       " 'trees': 4,\n",
       " 'user': 9}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.token2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skl_countvect = CountVectorizer(stop_words=stoplist,min_df=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skl_CountX = skl_countvect.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1],\n",
       "        [0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       "        [0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_CountX.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 0,\n",
       " 'eps': 1,\n",
       " 'graph': 2,\n",
       " 'human': 3,\n",
       " 'interface': 4,\n",
       " 'minors': 5,\n",
       " 'response': 6,\n",
       " 'survey': 7,\n",
       " 'system': 8,\n",
       " 'time': 9,\n",
       " 'trees': 10,\n",
       " 'user': 11}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_countvect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2, 1: 2, 2: 2, 3: 2, 4: 2, 5: 3, 6: 3, 7: 2, 8: 2, 9: 3, 10: 3, 11: 2}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
