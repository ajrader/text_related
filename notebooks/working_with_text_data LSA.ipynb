{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Lars Buitinck <L.J.Buitinck@uva.nl>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Usage: __main__.py [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --lsa=N_COMPONENTS    Preprocess documents with latent semantic analysis.\n",
      "  --no-minibatch        Use ordinary k-means algorithm (in batch mode).\n",
      "  --no-idf              Disable Inverse Document Frequency feature weighting.\n",
      "  --use-hashing         Use a hashing feature vectorizer\n",
      "  --n-features=N_FEATURES\n",
      "                        Maximum number of features (dimensions) to extract\n",
      "                        from text.\n",
      "  --verbose             Print progress reports inside k-means algorithm.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: __main__.py [options]\n",
      "\n",
      "__main__.py: error: no such option: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "# parse commandline arguments\n",
    "op = OptionParser()\n",
    "op.add_option(\"--lsa\",\n",
    "              dest=\"n_components\", type=\"int\",\n",
    "              help=\"Preprocess documents with latent semantic analysis.\")\n",
    "op.add_option(\"--no-minibatch\",\n",
    "              action=\"store_false\", dest=\"minibatch\", default=True,\n",
    "              help=\"Use ordinary k-means algorithm (in batch mode).\")\n",
    "op.add_option(\"--no-idf\",\n",
    "              action=\"store_false\", dest=\"use_idf\", default=True,\n",
    "              help=\"Disable Inverse Document Frequency feature weighting.\")\n",
    "op.add_option(\"--use-hashing\",\n",
    "              action=\"store_true\", default=False,\n",
    "              help=\"Use a hashing feature vectorizer\")\n",
    "op.add_option(\"--n-features\", type=int, default=10000,\n",
    "              help=\"Maximum number of features (dimensions)\"\n",
    "                   \" to extract from text.\")\n",
    "op.add_option(\"--verbose\",\n",
    "              action=\"store_true\", dest=\"verbose\", default=False,\n",
    "              help=\"Print progress reports inside k-means algorithm.\")\n",
    "\n",
    "print(__doc__)\n",
    "op.print_help()\n",
    "\n",
    "(opts, args) = op.parse_args()\n",
    "if len(args) > 0:\n",
    "    op.error(\"this script takes no arguments.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Load some categories from the training set\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "#categories = None\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034 documents\n",
      "4 categories\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dataset = fetch_20newsgroups(subset='all', categories=categories,\n",
    "#                             shuffle=True, random_state=42,download_if_missing = False)\n",
    "dataset = load_files('/home/kesj/scikit_learn_data/20news_home/20news-bydate-train/', categories=categories,\n",
    "                     shuffle=True, random_state=42,encoding='ISO-8859-1') # input is not utf-8 compliant\n",
    "\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = 10000\n",
    "\n",
    "use_idf = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from the training dataset using a sparse vectorizer\n",
      "done in 0.882731s\n",
      "n_samples: 2034, n_features: 10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = dataset.target\n",
    "true_k = np.unique(labels).shape[0]\n",
    "\n",
    "print(\"Extracting features from the training dataset using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "\"\"\"if opts.use_hashing:\n",
    "    if opts.use_idf:\n",
    "        # Perform an IDF normalization on the output of HashingVectorizer\n",
    "        hasher = HashingVectorizer(n_features=opts.n_features,\n",
    "                                   stop_words='english', non_negative=True,\n",
    "                                   norm=None, binary=False)\n",
    "        vectorizer = make_pipeline(hasher, TfidfTransformer())\n",
    "    else:\n",
    "        vectorizer = HashingVectorizer(n_features=opts.n_features,\n",
    "                                       stop_words='english',\n",
    "                                       non_negative=False, norm='l2',\n",
    "                                       binary=False)\n",
    "else:\n",
    "\"\"\"\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, max_features=n_features,\n",
    "                                 min_df=2, stop_words='english',\n",
    "                                 use_idf=use_idf)\n",
    "\n",
    "X = vectorizer.fit_transform(dataset.data)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_components= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing dimensionality reduction using LSA\n",
      "done in 0.623237s\n",
      "Explained variance of the SVD step: 27%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if n_components:\n",
    "    print(\"Performing dimensionality reduction using LSA\")\n",
    "    t0 = time()\n",
    "    # Vectorizer results are normalized, which makes KMeans behave as\n",
    "    # spherical k-means for better results. Since LSA/SVD results are\n",
    "    # not normalized, we have to redo the normalization.\n",
    "    svd = TruncatedSVD(n_components)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "    Xlsa = lsa.fit_transform(X)\n",
    "\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    print(\"Explained variance of the SVD step: {}%\".format(\n",
    "        int(explained_variance * 100)))\n",
    "\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 100 artists>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAFXCAYAAABKl4x5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f674c8ddeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(0,len(svd.explained_variance_ratio_)),svd.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=4, n_init=1,\n",
      "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
      "    verbose=True)\n",
      "Initialization complete\n",
      "Iteration  0, inertia 3222.438\n",
      "Iteration  1, inertia 1784.843\n",
      "Iteration  2, inertia 1752.376\n",
      "Iteration  3, inertia 1742.502\n",
      "Iteration  4, inertia 1739.737\n",
      "Iteration  5, inertia 1738.601\n",
      "Iteration  6, inertia 1738.107\n",
      "Iteration  7, inertia 1737.744\n",
      "Iteration  8, inertia 1737.586\n",
      "Iteration  9, inertia 1737.486\n",
      "Iteration 10, inertia 1737.262\n",
      "Iteration 11, inertia 1737.045\n",
      "Iteration 12, inertia 1736.675\n",
      "Iteration 13, inertia 1736.034\n",
      "Iteration 14, inertia 1735.430\n",
      "Iteration 15, inertia 1735.133\n",
      "Iteration 16, inertia 1734.966\n",
      "Iteration 17, inertia 1734.623\n",
      "Iteration 18, inertia 1733.887\n",
      "Iteration 19, inertia 1733.639\n",
      "Iteration 20, inertia 1733.534\n",
      "Iteration 21, inertia 1733.519\n",
      "Converged at iteration 21\n",
      "done in 0.054s\n",
      "\n",
      "Homogeneity: 0.678\n",
      "Completeness: 0.724\n",
      "V-measure: 0.700\n",
      "Adjusted Rand-Index: 0.694\n",
      "Silhouette Coefficient: 0.042\n",
      "\n",
      "Top terms per cluster:\n",
      "Cluster 0: god com people jesus sandvik don bible article think religion\n",
      "Cluster 1: keith caltech objective morality livesey sgi wpd solntze jon schneider\n",
      "Cluster 2: graphics image university thanks files com posting 3d host file\n",
      "Cluster 3: space nasa access com henry digex moon gov alaska orbit\n"
     ]
    }
   ],
   "source": [
    "minibatch = 0\n",
    "use_hashing=False\n",
    "###############################################################################\n",
    "# Do the actual clustering\n",
    "\n",
    "if minibatch:\n",
    "    km = MiniBatchKMeans(n_clusters=true_k, init='k-means++', n_init=1,\n",
    "                         init_size=1000, batch_size=1000, verbose=True)\n",
    "else:\n",
    "    km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1,\n",
    "                verbose=True)\n",
    "\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(Xlsa)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(Xlsa, km.labels_, sample_size=1000))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "if not use_hashing:\n",
    "    print(\"Top terms per cluster:\")\n",
    "\n",
    "    if n_components:\n",
    "        original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "        order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "    else:\n",
    "        order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(true_k):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering sparse data with MiniBatchKMeans(batch_size=1000, compute_labels=True, init='k-means++',\n",
      "        init_size=1000, max_iter=100, max_no_improvement=10, n_clusters=4,\n",
      "        n_init=1, random_state=None, reassignment_ratio=0.01, tol=0.0,\n",
      "        verbose=True)\n",
      "Init 1/1 with method: k-means++\n",
      "Inertia for init 1/1: 873.970866\n",
      "Minibatch iteration 1/300: mean batch inertia: 0.880721, ewa inertia: 0.880721 \n",
      "Minibatch iteration 2/300: mean batch inertia: 0.867977, ewa inertia: 0.868196 \n",
      "Minibatch iteration 3/300: mean batch inertia: 0.862499, ewa inertia: 0.862597 \n",
      "Minibatch iteration 4/300: mean batch inertia: 0.861945, ewa inertia: 0.861957 \n",
      "Minibatch iteration 5/300: mean batch inertia: 0.862798, ewa inertia: 0.862783 \n",
      "Minibatch iteration 6/300: mean batch inertia: 0.858739, ewa inertia: 0.858809 \n",
      "Minibatch iteration 7/300: mean batch inertia: 0.865467, ewa inertia: 0.865353 \n",
      "Minibatch iteration 8/300: mean batch inertia: 0.858589, ewa inertia: 0.858705 \n",
      "Minibatch iteration 9/300: mean batch inertia: 0.853247, ewa inertia: 0.853340 \n",
      "Minibatch iteration 10/300: mean batch inertia: 0.859595, ewa inertia: 0.859488 \n",
      "Minibatch iteration 11/300: mean batch inertia: 0.856319, ewa inertia: 0.856373 \n",
      "Minibatch iteration 12/300: mean batch inertia: 0.860129, ewa inertia: 0.860065 \n",
      "Minibatch iteration 13/300: mean batch inertia: 0.860363, ewa inertia: 0.860358 \n",
      "Minibatch iteration 14/300: mean batch inertia: 0.858291, ewa inertia: 0.858327 \n",
      "Minibatch iteration 15/300: mean batch inertia: 0.856202, ewa inertia: 0.856239 \n",
      "Minibatch iteration 16/300: mean batch inertia: 0.849770, ewa inertia: 0.849882 \n",
      "Minibatch iteration 17/300: mean batch inertia: 0.861585, ewa inertia: 0.861384 \n",
      "Minibatch iteration 18/300: mean batch inertia: 0.856099, ewa inertia: 0.856190 \n",
      "Minibatch iteration 19/300: mean batch inertia: 0.853964, ewa inertia: 0.854002 \n",
      "Minibatch iteration 20/300: mean batch inertia: 0.857733, ewa inertia: 0.857669 \n",
      "Minibatch iteration 21/300: mean batch inertia: 0.857556, ewa inertia: 0.857558 \n",
      "Minibatch iteration 22/300: mean batch inertia: 0.857208, ewa inertia: 0.857214 \n",
      "Minibatch iteration 23/300: mean batch inertia: 0.853278, ewa inertia: 0.853346 \n",
      "Minibatch iteration 24/300: mean batch inertia: 0.857709, ewa inertia: 0.857634 \n",
      "Minibatch iteration 25/300: mean batch inertia: 0.856772, ewa inertia: 0.856787 \n",
      "Minibatch iteration 26/300: mean batch inertia: 0.861066, ewa inertia: 0.860992 \n",
      "Converged (lack of improvement in inertia) at iteration 26/300\n",
      "Computing label assignment and total inertia\n",
      "done in 0.137s\n",
      "\n",
      "Homogeneity: 0.634\n",
      "Completeness: 0.743\n",
      "V-measure: 0.684\n",
      "Adjusted Rand-Index: 0.639\n",
      "Silhouette Coefficient: 0.043\n",
      "\n",
      "Top terms per cluster:\n",
      "Cluster 0: god com people don article keith jesus think sandvik say\n",
      "Cluster 1: henry toronto zoo spencer zoology work utzoo kipling article launch\n",
      "Cluster 2: space nasa access com gov alaska moon digex pat shuttle\n",
      "Cluster 3: graphics university thanks image files com posting host nntp 3d\n"
     ]
    }
   ],
   "source": [
    "minibatch = 1\n",
    "use_hashing=False\n",
    "###############################################################################\n",
    "# Do the actual clustering\n",
    "\n",
    "if minibatch:\n",
    "    km = MiniBatchKMeans(n_clusters=true_k, init='k-means++', n_init=1,\n",
    "                         init_size=1000, batch_size=1000, verbose=True)\n",
    "else:\n",
    "    km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1,\n",
    "                verbose=True)\n",
    "\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(Xlsa)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(Xlsa, km.labels_, sample_size=1000))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "if not use_hashing:\n",
    "    print(\"Top terms per cluster:\")\n",
    "\n",
    "    if n_components:\n",
    "        original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "        order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "    else:\n",
    "        order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(true_k):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47613781,  0.29199845, -0.01392281, -0.43450938,  0.42529957,\n",
       "         0.42043609,  0.05475372,  0.06471751, -0.02797768, -0.0390973 ,\n",
       "        -0.00686906, -0.12182542,  0.01862731,  0.0410083 , -0.14024352,\n",
       "         0.15225497,  0.14242073,  0.16323901, -0.12616133, -0.09632821]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
